# Falcon-7B Fine-tuning Project

A production-ready ML engineering project for fine-tuning Falcon-7B using QLoRA and TRL, following industry best practices.

## ğŸš€ Features

- **Modular Architecture**: Clean separation of concerns with reusable components
- **Reproducible Experiments**: Seed management and experiment tracking
- **Configuration Management**: YAML-based configuration system
- **Comprehensive Testing**: Unit tests for all components
- **CI/CD Pipeline**: Automated testing and deployment
- **Data Versioning**: DVC integration for dataset management
- **Monitoring & Logging**: MLflow integration for experiment tracking
- **Type Safety**: Full type hints and validation

## ğŸ“ Project Structure

```
falcon-7b-finetuning/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ cd.yml
â”‚       â””â”€â”€ model-training.yml
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ falcon-7b.yaml
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ default.yaml
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ guanaco.yaml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â””â”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ falcon.py
â”‚   â”‚   â””â”€â”€ base.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ callbacks.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ reproducibility.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data/
â”‚   â”œâ”€â”€ test_models/
â”‚   â”œâ”€â”€ test_training/
â”‚   â””â”€â”€ test_utils/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ setup_environment.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ final/
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ dvc.yaml
â””â”€â”€ README.md
```

## ğŸ› ï¸ Setup

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended)
- Git
- DVC (for data versioning)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/behroozazarkhalili/falcon-7b-finetuning.git
   cd falcon-7b-finetuning
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   # or using conda
   conda env create -f environment.yml
   ```

4. **Setup pre-commit hooks**
   ```bash
   pre-commit install
   ```

5. **Initialize DVC**
   ```bash
   dvc init
   ```

6. **Setup MLflow tracking**
   ```bash
   mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns
   ```

## ğŸš€ Usage

### Training

```bash
python scripts/train.py --config configs/training/default.yaml
```

### Evaluation

```bash
python scripts/evaluate.py --model-path models/final/falcon-7b-finetuned --config configs/training/default.yaml
```

### Inference

```bash
python scripts/inference.py --model-path models/final/falcon-7b-finetuned --prompt "Your prompt here"
```

### Configuration

All configurations are stored in YAML files under the `configs/` directory. You can modify hyperparameters, model settings, and data configurations without changing the code.

Example training configuration:
```yaml
model:
  name: "tiiuae/falcon-7b"
  quantization:
    load_in_4bit: true
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_compute_dtype: "float16"
    bnb_4bit_use_double_quant: true

training:
  output_dir: "./results"
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  num_train_epochs: 5
  max_seq_length: 512
```

## ğŸ§ª Testing

Run all tests:
```bash
pytest tests/ -v
```

Run specific test categories:
```bash
pytest tests/test_models/ -v
pytest tests/test_data/ -v
```

## ğŸ“Š Monitoring

- **MLflow**: Track experiments at `http://localhost:5000`
- **Logs**: Check `logs/` directory for detailed training logs
- **Metrics**: Model performance metrics are logged automatically

## ğŸ”„ CI/CD

The project includes GitHub Actions workflows for:
- **Continuous Integration**: Automated testing on pull requests
- **Continuous Deployment**: Model deployment on main branch
- **Model Training**: Scheduled retraining pipeline

## ğŸ“ˆ Data Management

- Raw data is stored in `data/raw/`
- Processed data is stored in `data/processed/`
- Data versioning is handled by DVC
- Dataset schemas are documented in `configs/data/`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests (`pytest`)
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Hugging Face for the Transformers library
- TRL team for the training framework
- Falcon team for the base model 